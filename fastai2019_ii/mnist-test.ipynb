{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "political-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.datasets import MNIST \n",
    "from torchvision import transforms \n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "\n",
    "from exp.nb_02 import * \n",
    "\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "  def forward(self,img):\n",
    "    img_shape = img.shape\n",
    "    return img.view(img_shape[0],img_shape[1]*img_shape[2])\n",
    "\n",
    "mnist_tnfs = transforms.Compose([transforms.ToTensor(),Flatten()])\n",
    "\n",
    "\n",
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bright-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sharp-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNISTDataset(x_train,y_train)\n",
    "test = MNISTDataset(x_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "northern-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bs=128\n",
    "train_dl = DataLoader(train,bs,shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(test,bs,shuffle=False)\n",
    "\n",
    "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "extra-outside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[20].view(28,28))\n",
    "y_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "professional-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n,m = len(train),train[0][0].shape[0]\n",
    "c = y_train.max()+1\n",
    "nh = 10\n",
    "\n",
    "lr = 0.01   # learning rate\n",
    "epochs = 30 # how many epochs to train for\n",
    "n,m,c,lr,epochs\n",
    "\n",
    "class MNISTNN(torch.nn.Module):\n",
    "  def __init__(self,m,nh,c):\n",
    "    super(MNISTNN, self).__init__()\n",
    "    self.lin1 = torch.nn.Linear(m,nh)\n",
    "    self.act1 = torch.nn.ReLU()\n",
    "    self.out = torch.nn.Linear(nh,10)\n",
    "  \n",
    "  def forward(self,xb):\n",
    "    xb = xb.squeeze(1)\n",
    "    return self.out(self.act1(self.lin1(xb)))\n",
    "\n",
    "loss_func = F.cross_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "compliant-mountain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.7908, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xb,yb = next(iter(valid_dl))\n",
    "assert xb.shape==(bs,28*28)\n",
    "assert yb.shape==(bs,)\n",
    "\n",
    "model = MNISTNN(m,nh,c)\n",
    "\n",
    "model.lin1.bias\n",
    "\n",
    "model_layers = ['lin1','out']\n",
    "\n",
    "loss_func(model(xb), yb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "threaded-fetish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTNN(\n",
       "  (lin1): Linear(in_features=784, out_features=10, bias=True)\n",
       "  (act1): ReLU()\n",
       "  (out): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "nutritional-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fit(epochs, model, loss_func, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Handle batchnorm / dropout\n",
    "        model.train()\n",
    "#         print(model.training)\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for layer_name in model_layers:\n",
    "                    l = getattr(model,layer_name)\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias  .grad.zero_()\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "#         print(model.training)\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb)\n",
    "                tot_acc  += accuracy (pred,yb)\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "departmental-internet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(2.1166) tensor(0.1897)\n",
      "1 tensor(2.1056) tensor(0.1942)\n",
      "2 tensor(2.0658) tensor(0.2037)\n",
      "3 tensor(2.0670) tensor(0.2039)\n",
      "4 tensor(2.0435) tensor(0.2084)\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "model = MNISTNN(m,nh,c)\n",
    "loss,acc = fit(5, model, loss_func, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "analyzed-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Handle batchnorm / dropout\n",
    "        model.train()\n",
    "#         print(model.training)\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        model.eval()\n",
    "#         print(model.training)\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb)\n",
    "                tot_acc  += accuracy (pred,yb)\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "comparable-major",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(2.1705) tensor(0.1579)\n",
      "1 tensor(2.1260) tensor(0.1866)\n",
      "2 tensor(2.1123) tensor(0.1906)\n",
      "3 tensor(2.3215) tensor(0.1138)\n",
      "4 tensor(2.3228) tensor(0.1140)\n"
     ]
    }
   ],
   "source": [
    "model = MNISTNN(m,nh,c)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "french-dominant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MNISTDataset at 0x7f89614575f8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-reviewer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
