{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Residual Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An operation on layers \n",
    "# consider a layer L\n",
    "def L(*args):return args[0]\n",
    "l0 = 0\n",
    "# Non residual Layer \n",
    "l1 = L(l0)\n",
    "\n",
    "# Residual Layer. \n",
    "l1 = l0 + L(l0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variations in Residual Connections? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Natural and artificial neurons\" width=\"500\" caption=\"Variations in Res Connections\" src=\"images/Variations_Res_Conns.png\" id=\"neuron\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is BatchNorm? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "m = nn.BatchNorm1d(100)\n",
    "input = torch.randn(20, 100)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9923)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9705, grad_fn=<StdBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explainations:\n",
    "    * [Andrew Ng](https://www.youtube.com/watch?v=tNIpEZLv_eg&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&index=27)\n",
    "    * [Jeremy Howard](https://youtu.be/hkBa9pU-H48)\n",
    "##  Purpose: \n",
    "  * Makes Hyperparameter search much easier. \n",
    "  * Bigger range of HP can be made to work\n",
    "  * Helps train deeper models\n",
    "  * has slight regulatization effect due to added noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the inputs to layers:\n",
    "    # * Debate about normalizing before and after activations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Natural and artificial neurons\" width=\"500\" caption=\"batch norm nlp\" src=\"images/batch_norm_mlp.png\" id=\"neuron\"/>\n",
    "\n",
    "<img alt=\"Natural and artificial neurons\" width=\"500\" caption=\"batch norm nlp\" src=\"images/batch_norm_equations.png\" id=\"neuron\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose of HyperParams in Batch Norm: \n",
    "    * We might not want the mean and variance to be 0 and 1. \n",
    "        * With it's effect on activation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is exponentially Weighted Moving Averages? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Natural and artificial neurons\" width=\"500\" caption=\"batch norm nlp\" src=\"images/ewml.png\" id=\"neuron\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why does Batch Norm Work?  (Explain Internal CoVariate Shift)\n",
    "https://www.youtube.com/watch?v=nUUqwaxLnWs&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&index=29\n",
    "\n",
    "#### Internal CoVariate Shift\n",
    ">    We define Internal Covariate Shift as the change in the\n",
    "    distribution of network activations due to the change in\n",
    "    network parameters during training. To improve the train-\n",
    "    ing, we seek to reduce the internal covariate shift.\n",
    "   \n",
    "    - Batch Norm Paper \n",
    "\n",
    "The problem deeper layers suffer from are that even if the input stays the same the activations of the previous layers keep changing (due to their wieghts changing). So, in an effort to keep the activations in similar areas (alpha and beta of batchnorm) we use batch norm. Thus, this enhances learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do we need to change BatchNorm in Test: \n",
    "    * Yes. Since we process examples one item at a time so mean and std might not be good. \n",
    "        * Soln: Keep a running average of mean and std which is used with examples during test. \n",
    "        \n",
    "### Pytorch Soln: https://discuss.pytorch.org/t/what-does-model-eval-do-for-batchnorm-layer/7146/2\n",
    "### Jeremy FastAI Explaination: https://course19.fast.ai/videos/?lesson=10&t=5899\n",
    "### PyTorch LERP: https://pytorch.org/docs/stable/generated/torch.lerp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Paper Insights: \n",
    "\n",
    "Things have been tried before. \n",
    "Normal norm doesn't work. \n",
    "Training is needed. alpa and beta are being used to widen the data differently. \n",
    "\n",
    "\"We want to perform the identity transformer. Norm doesn't do that. alpha and beta help in identity transform.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755) AxesSubplot(0.125,0.125;0.775x0.755) AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "import pandas as pd \n",
    "\n",
    "model_dict = torch.load('/home/vimarshc/Documents/models/resnet18_pytorch/resnet18-f37072fd.pth')\n",
    "model_keys = model_dict.keys()\n",
    "bn_keys = [it_key for it_key in model_keys if ('weight' in it_key or 'bias' in it_key) and 'bn' in it_key ]\n",
    "model = models.resnet18()\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "bn_weight_keys = [it for it in bn_keys if 'weight' in it]\n",
    "bn_bias_keys = [it for it in bn_keys if 'bias' in it]\n",
    "\n",
    "dfbn = pd.DataFrame({'bn_tag':bn_weight_keys})\n",
    "dfbn['weight_shape'] = dfbn['bn_tag'].apply(lambda x: model_dict[x].shape[0])\n",
    "dfbn['weight_mean'] = dfbn['bn_tag'].apply(lambda x: float(model_dict[x].mean()))\n",
    "dfbn['bias_keys'] = bn_bias_keys\n",
    "dfbn['bias_mean'] = dfbn['bias_keys'].apply(lambda x: float(model_dict[x].mean()))\n",
    "dfbn['weight_name'] = dfbn['bn_tag'].apply(lambda x: x.replace('bn','conv'))\n",
    "dfbn['conv_weight_mean'] = dfbn['weight_name'].apply(lambda x: float(model_dict[x].mean()))\n",
    "print(dfbn.weight_mean.plot(),dfbn.bias_mean.plot(),dfbn.conv_weight_mean.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bn_tag</th>\n",
       "      <th>weight_shape</th>\n",
       "      <th>weight_mean</th>\n",
       "      <th>bias_keys</th>\n",
       "      <th>bias_mean</th>\n",
       "      <th>weight_name</th>\n",
       "      <th>conv_weight_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bn1.weight</td>\n",
       "      <td>64</td>\n",
       "      <td>0.257577</td>\n",
       "      <td>bn1.bias</td>\n",
       "      <td>0.181120</td>\n",
       "      <td>conv1.weight</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layer1.0.bn1.weight</td>\n",
       "      <td>64</td>\n",
       "      <td>0.339601</td>\n",
       "      <td>layer1.0.bn1.bias</td>\n",
       "      <td>-0.034137</td>\n",
       "      <td>layer1.0.conv1.weight</td>\n",
       "      <td>-0.003087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>layer1.0.bn2.weight</td>\n",
       "      <td>64</td>\n",
       "      <td>0.333055</td>\n",
       "      <td>layer1.0.bn2.bias</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>layer1.0.conv2.weight</td>\n",
       "      <td>-0.000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>layer1.1.bn1.weight</td>\n",
       "      <td>64</td>\n",
       "      <td>0.328692</td>\n",
       "      <td>layer1.1.bn1.bias</td>\n",
       "      <td>-0.083574</td>\n",
       "      <td>layer1.1.conv1.weight</td>\n",
       "      <td>-0.002420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>layer1.1.bn2.weight</td>\n",
       "      <td>64</td>\n",
       "      <td>0.392430</td>\n",
       "      <td>layer1.1.bn2.bias</td>\n",
       "      <td>-0.029984</td>\n",
       "      <td>layer1.1.conv2.weight</td>\n",
       "      <td>-0.001260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>layer2.0.bn1.weight</td>\n",
       "      <td>128</td>\n",
       "      <td>0.316419</td>\n",
       "      <td>layer2.0.bn1.bias</td>\n",
       "      <td>-0.067346</td>\n",
       "      <td>layer2.0.conv1.weight</td>\n",
       "      <td>-0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>layer2.0.bn2.weight</td>\n",
       "      <td>128</td>\n",
       "      <td>0.327573</td>\n",
       "      <td>layer2.0.bn2.bias</td>\n",
       "      <td>-0.003555</td>\n",
       "      <td>layer2.0.conv2.weight</td>\n",
       "      <td>-0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>layer2.1.bn1.weight</td>\n",
       "      <td>128</td>\n",
       "      <td>0.321264</td>\n",
       "      <td>layer2.1.bn1.bias</td>\n",
       "      <td>-0.210250</td>\n",
       "      <td>layer2.1.conv1.weight</td>\n",
       "      <td>-0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>layer2.1.bn2.weight</td>\n",
       "      <td>128</td>\n",
       "      <td>0.282911</td>\n",
       "      <td>layer2.1.bn2.bias</td>\n",
       "      <td>-0.151284</td>\n",
       "      <td>layer2.1.conv2.weight</td>\n",
       "      <td>-0.001272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>layer3.0.bn1.weight</td>\n",
       "      <td>256</td>\n",
       "      <td>0.312275</td>\n",
       "      <td>layer3.0.bn1.bias</td>\n",
       "      <td>-0.114786</td>\n",
       "      <td>layer3.0.conv1.weight</td>\n",
       "      <td>-0.001368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>layer3.0.bn2.weight</td>\n",
       "      <td>256</td>\n",
       "      <td>0.320250</td>\n",
       "      <td>layer3.0.bn2.bias</td>\n",
       "      <td>-0.030766</td>\n",
       "      <td>layer3.0.conv2.weight</td>\n",
       "      <td>-0.000787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>layer3.1.bn1.weight</td>\n",
       "      <td>256</td>\n",
       "      <td>0.278211</td>\n",
       "      <td>layer3.1.bn1.bias</td>\n",
       "      <td>-0.237468</td>\n",
       "      <td>layer3.1.conv1.weight</td>\n",
       "      <td>-0.001662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>layer3.1.bn2.weight</td>\n",
       "      <td>256</td>\n",
       "      <td>0.245850</td>\n",
       "      <td>layer3.1.bn2.bias</td>\n",
       "      <td>-0.163723</td>\n",
       "      <td>layer3.1.conv2.weight</td>\n",
       "      <td>-0.001441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>layer4.0.bn1.weight</td>\n",
       "      <td>512</td>\n",
       "      <td>0.264318</td>\n",
       "      <td>layer4.0.bn1.bias</td>\n",
       "      <td>-0.225722</td>\n",
       "      <td>layer4.0.conv1.weight</td>\n",
       "      <td>-0.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>layer4.0.bn2.weight</td>\n",
       "      <td>512</td>\n",
       "      <td>0.424319</td>\n",
       "      <td>layer4.0.bn2.bias</td>\n",
       "      <td>-0.197634</td>\n",
       "      <td>layer4.0.conv2.weight</td>\n",
       "      <td>-0.001303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>layer4.1.bn1.weight</td>\n",
       "      <td>512</td>\n",
       "      <td>0.288600</td>\n",
       "      <td>layer4.1.bn1.bias</td>\n",
       "      <td>-0.241740</td>\n",
       "      <td>layer4.1.conv1.weight</td>\n",
       "      <td>-0.002261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>layer4.1.bn2.weight</td>\n",
       "      <td>512</td>\n",
       "      <td>1.853810</td>\n",
       "      <td>layer4.1.bn2.bias</td>\n",
       "      <td>0.273822</td>\n",
       "      <td>layer4.1.conv2.weight</td>\n",
       "      <td>-0.000108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bn_tag  weight_shape  weight_mean          bias_keys  \\\n",
       "0            bn1.weight            64     0.257577           bn1.bias   \n",
       "1   layer1.0.bn1.weight            64     0.339601  layer1.0.bn1.bias   \n",
       "2   layer1.0.bn2.weight            64     0.333055  layer1.0.bn2.bias   \n",
       "3   layer1.1.bn1.weight            64     0.328692  layer1.1.bn1.bias   \n",
       "4   layer1.1.bn2.weight            64     0.392430  layer1.1.bn2.bias   \n",
       "5   layer2.0.bn1.weight           128     0.316419  layer2.0.bn1.bias   \n",
       "6   layer2.0.bn2.weight           128     0.327573  layer2.0.bn2.bias   \n",
       "7   layer2.1.bn1.weight           128     0.321264  layer2.1.bn1.bias   \n",
       "8   layer2.1.bn2.weight           128     0.282911  layer2.1.bn2.bias   \n",
       "9   layer3.0.bn1.weight           256     0.312275  layer3.0.bn1.bias   \n",
       "10  layer3.0.bn2.weight           256     0.320250  layer3.0.bn2.bias   \n",
       "11  layer3.1.bn1.weight           256     0.278211  layer3.1.bn1.bias   \n",
       "12  layer3.1.bn2.weight           256     0.245850  layer3.1.bn2.bias   \n",
       "13  layer4.0.bn1.weight           512     0.264318  layer4.0.bn1.bias   \n",
       "14  layer4.0.bn2.weight           512     0.424319  layer4.0.bn2.bias   \n",
       "15  layer4.1.bn1.weight           512     0.288600  layer4.1.bn1.bias   \n",
       "16  layer4.1.bn2.weight           512     1.853810  layer4.1.bn2.bias   \n",
       "\n",
       "    bias_mean            weight_name  conv_weight_mean  \n",
       "0    0.181120           conv1.weight          0.000029  \n",
       "1   -0.034137  layer1.0.conv1.weight         -0.003087  \n",
       "2    0.003463  layer1.0.conv2.weight         -0.000889  \n",
       "3   -0.083574  layer1.1.conv1.weight         -0.002420  \n",
       "4   -0.029984  layer1.1.conv2.weight         -0.001260  \n",
       "5   -0.067346  layer2.0.conv1.weight         -0.001454  \n",
       "6   -0.003555  layer2.0.conv2.weight         -0.001248  \n",
       "7   -0.210250  layer2.1.conv1.weight         -0.001530  \n",
       "8   -0.151284  layer2.1.conv2.weight         -0.001272  \n",
       "9   -0.114786  layer3.0.conv1.weight         -0.001368  \n",
       "10  -0.030766  layer3.0.conv2.weight         -0.000787  \n",
       "11  -0.237468  layer3.1.conv1.weight         -0.001662  \n",
       "12  -0.163723  layer3.1.conv2.weight         -0.001441  \n",
       "13  -0.225722  layer4.0.conv1.weight         -0.001565  \n",
       "14  -0.197634  layer4.0.conv2.weight         -0.001303  \n",
       "15  -0.241740  layer4.1.conv1.weight         -0.002261  \n",
       "16   0.273822  layer4.1.conv2.weight         -0.000108  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfbn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Batch Norm Help with ICS? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Natural and artificial neurons\" width=\"500\" caption=\"batch norm nlp\" src=\"images/batch_norm_ics.png\" id=\"neuron\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Covariate Shift? \n",
    "Training set and Query / Test set having very different distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Natural and artificial neurons\" width=\"500\" caption=\"batch norm nlp\" src=\"images/index.jpeg\" id=\"neuron\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to detect: \n",
    "    * dimensional reduction: tsne\n",
    "    * membership modelling: \n",
    "          * One class SVM\n",
    "          * Uncertainty Quantification: Prob\n",
    "          * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the Purpose of Initilization? \n",
    "We want the inputs of all layers to be between mean = 0 and std = 1\n",
    "\n",
    "# Example? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 50\n",
    "m = 764\n",
    "\n",
    "# standard xavier init\n",
    "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
    "b2 = torch.zeros(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10000,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, m, s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = normalize(x,x.mean(),x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\"\n",
    "\n",
    "test_near_zero(x.mean())\n",
    "test_near_zero(1-x.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Learning Rate? \n",
    "### How is it used? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "import pandas as pd \n",
    "\n",
    "model_dict = torch.load('/home/vimarshc/Documents/models/resnet18_pytorch/resnet18-f37072fd.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18()\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Cross-Entropy? \n",
    "\n",
    "\n",
    "\n",
    "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
    "$$ -\\sum x\\, \\log p(x) $$\n",
    "\n",
    "But since our $x$s are 1-hot encoded, this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target.\n",
    "\n",
    "This can be done using numpy-style integer array indexing. Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 5, 1, 9, 2, 3, 8, 1, 7])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.randn(1000,10)\n",
    "targets = torch.tensor(numpy.random.randint(0,10, size=1000))\n",
    "# Sample of 1000 predictions from MNIST \n",
    "# 10 is num of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-b0ec4e842cf5>:1: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logged_softmax = F.log_softmax(preds)\n"
     ]
    }
   ],
   "source": [
    "logged_softmax = F.log_softmax(preds)\n",
    "# More numerically stable\n",
    "# https://discuss.pytorch.org/t/what-is-the-difference-between-log-softmax-and-softmax/11801/7\n",
    "\n",
    "# The gradient calculation for cross entropy -sum(target*log(p)) is much nicer \n",
    "# https://stats.stackexchange.com/questions/289369/log-probabilities-in-reference-to-softmax-classifier\n",
    "\n",
    "# Numerical Stability: Taking their word here. \n",
    "# https://stats.stackexchange.com/questions/174481/why-to-optimize-max-log-probability-instead-of-probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input,target): return -input[range(target.shape[0]),target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7029)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(logged_softmax,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
