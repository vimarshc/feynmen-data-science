{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Forbenius Norm? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Frobenius norm:\n",
    "$$\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tensor([[1., 2, 3], [4,5,6], [7,8,9]]); m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.8819)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m*m).sum().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Variance? \n",
    "For a set of data points it is the average of how far each data point is away from the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "t = torch.tensor([1.,2.,4.,18])\n",
    "m = t.mean(); m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t-m).mean() #WRONG:  Positives and Negs canceling each other out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47.1875)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t-m).pow(2).mean() # Soln1 Square everything to avoid Canceling\n",
    "# Called Variance Now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the first of these is now a totally different scale, since we squared. So let's undo that at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.8693)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t-m).pow(2).mean().sqrt() # Unsquaring Now: Called std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.8750)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t-m).abs().mean() # Mean Absolute Deviation . Soln 2. Take abs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name one con of std() over Mean Absolute Deviation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of 18 (an outlier) in our dataset, the square of 18 increases the sum by a lot. Thus, STD() is quite suseptible to outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "They're still different. Why?\n",
    "\n",
    "Note that we have one outlier (`18`). In the version where we square everything, it makes that much bigger than everything else.\n",
    "\n",
    "`(t-m).pow(2).mean()` is refered to as **variance**. It's a measure of how spread out the data is, and is particularly sensitive to outliers.\n",
    "\n",
    "When we take the sqrt of the variance, we get the **standard deviation**. Since it's on the same kind of scale as the original data, it's generally more interpretable. However, since `sqrt(1)==1`, it doesn't much matter which we use when talking about *unit variance* for initializing neural nets.\n",
    "\n",
    "`(t-m).abs().mean()` is referred to as the **mean absolute deviation**. It isn't used nearly as much as it deserves to be, because mathematicians don't like how awkward it is to work with. But that shouldn't stop us, because we have computers and stuff.\n",
    "\n",
    "Here's a useful thing to note about variance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the alternate version (formula) of the variance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(47.1875), tensor(47.1875))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1.,2.,4.,18])\n",
    "m = t.mean()\n",
    "(t-m).pow(2).mean(), (t*t).mean() - (m*m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see why these are equal if you want to work thru the algebra. Or not.\n",
    "\n",
    "But, what's important here is that the latter is generally much easier to work with. In particular, you only have to track two things: the sum of the data, and the sum of squares of the data. Whereas in the first form you actually have to go thru all the data twice (once to calculate the mean, once to calculate the differences).\n",
    "\n",
    "Let's go steal the LaTeX from [Wikipedia](https://en.wikipedia.org/wiki/Variance):\n",
    "\n",
    "$$\\operatorname{E}\\left[X^2 \\right] - \\operatorname{E}[X]^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance of a Dot Product? \n",
    "if I have: \n",
    "$$ Y = a.b $$ \n",
    "\n",
    "Define Var of Y in terms of Var of a and b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance and correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how Wikipedia defines covariance:\n",
    "\n",
    "$$\\operatorname{cov}(X,Y) = \\operatorname{E}{\\big[(X - \\operatorname{E}[X])(Y - \\operatorname{E}[Y])\\big]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1.,2.,4.,18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# `u` is twice `t`, plus a bit of randomness\n",
    "u = t*2\n",
    "u *= torch.randn_like(t)/10+0.95\n",
    "\n",
    "plt.scatter(t, u);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 51.3526,  34.7343,  10.9100, 267.9366])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod = (t-t.mean())*(u-u.mean()); prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91.2334)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = torch.randn_like(t)\n",
    "plt.scatter(t, v);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5255)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((t-t.mean())*(v-v.mean())).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a measure of how lined up two sets of variables are. Higher the cov higher the lined up ness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In probability theory and statistics, covariance is a measure of the joint variability of two random variables.[1] **If the greater values of one variable mainly correspond with the greater values of the other variable, and the same holds for the lesser values (that is, the variables tend to show similar behavior), the covariance is positive**.[2] In the opposite case, when the greater values of one variable mainly correspond to the lesser values of the other, (that is, the variables tend to show opposite behavior), the covariance is negative. The sign of the covariance therefore shows the **tendency in the linear relationship between the variables** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/covariance.png\" alt=\"Drawing\" style=\"width: 100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the alternate representation of cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's generally more conveniently defined like so:\n",
    "\n",
    "$$\\operatorname{E}\\left[X Y\\right] - \\operatorname{E}\\left[X\\right] \\operatorname{E}\\left[Y\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5255)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = (t*v).mean() - t.mean()*v.mean(); cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain how Covariance and Variance are the Same thing. \n",
    "\n",
    "Substitute Y with X in convariance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Correlation? Given Covariance and Variance can you now derive a normalized version of covariance, a ratio to show the relationship between two random variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized Covariance \n",
    "$$\\rho_{X,Y}= \\frac{\\operatorname{cov}(X,Y)}{\\sigma_X \\sigma_Y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Correlation between X and X? \n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most efficient to Calculate Softmax via code? \n",
    "Best way to calculate softmax is to calculate logsoftmax instead. You will be using CrossEntropyLoss which is $$ -\\sum x\\, \\log p(x) $$\n",
    "So it is better to compute the log before hand as computationally it is easier to compute the `logsumexp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.logsumexp(-1,True)\n",
    "def softmax(x): return x.exp()/x.exp().sum(-1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  4., 18.])\n",
      "tensor([-17., -16., -14.,   0.])\n",
      "tensor([4.1399e-08, 1.1254e-07, 8.3153e-07, 1.0000e+00])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-c6416e25f7b8>:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(t)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4.1399e-08, 1.1254e-07, 8.3153e-07, 1.0000e+00])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t)\n",
    "print(log_softmax(t))\n",
    "print(softmax(t))\n",
    "from torch.nn import functional as F \n",
    "F.softmax(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
